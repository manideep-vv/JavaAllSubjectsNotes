still didnt understand what is use of setting true
================
1) auto.offset.reset=true what does it means?
i think  this will work only for un comitted offsets 
if u have already committed offsets till 500 , even if u start 10 times al
if u want to re consume the messages ha only way is dont commit the offsets

Try without comitting the offsets and if u start and stop u will consume all messages once again

2) add shut down hook for graceful shutdown
=============================================
means add some task to that. so that jvm while its going to shutdown it will execute that task
consumer graceful shut down - while shutting down u have to interrupt that consumer thread and we have to wait for that main 
3) practice consumer.poll
3) practice consumer group rebalance with graceful shut down- make 3 consumers working in same group to read from 3 partitions and let 1 consumer die with graceful shutdown and only because of graceful shutdown groups will rebalance -try without graceful shutdown will groups rebalance properly ??
check if existing 2 consumers reading from 3 partitions or not

i think even if it is graceful shutdown or not anyways consumer will join the group and shares the partition based on the rebalance partition assignment strategy it will join 
5) only for static group members will that session timeout work??? for non static group members will that work???
6) what is auto.offset.reset=earliest vs latest
FIX THE CONSUMER GROUP  and make it as earliest & down  the consumer and send and come back and see if those earlier messages are coming or not
follow the above procedure and make as latest and see thoe messages

new consumer group with latest 
new consumer group with earliest

sent 700 messages to the topic
1) configure consumergroup id as "tcs-group"  and auto.offset.reset=earliest  -- this is a new consumer group
since this is a new consumer group it consumed all messages in the topic

2) configure consumergroup id as "2.tcs-group" and auto.offset.reset=earliest -- this is a new consumer group
since this is a new consumer group it consumed all 700 messages in the topic

3)configure consumergroup id as "1.infosys-group" and auto.offset.reset=latest --this is also a new consumer group 
but it is reset to latest
4) try batch processing and get 1000 records and throw some exceptions fter processinng 900 records or shut down the consumer afer processing 900 records by keeping some thread.sleep and make the consumer live after that and 
see the impact by changing 
1) auto commit enable and disable- see if we can process all 1000 records
2) change the auto commit interval time and see if we can get all 1000 records
first disable auto commit and enable manual commit and do commit at last and check
3)Make sure u should not re-process all those records  and u should process all those 1000 records only single time
case:- 
what if consumer went down after processing those 1000 records and before commit, only consumer.commitAsync() is pending and if it came back after that will reprocess all those 1000 records??
4) check the backoff mechanism
@RetryableTopic(attempts = 5,
    backoff = @Backoff(delay = 1000, multiplier = 2, maxDelay = 5000))
@KafkaListener(topics = "my-annotated-topic")
The above is an exponential backoff first time it will retry after 1 second
and see if it is retrying that message from which topic??
5) in case of null pointer exceptions -it will retry 10 times 
check how and from which topic its getting retried 
6) log compaction in console -- and observe the offsets-try both deleting based on age of data, and delete based on old keys
7) observe the timestamp/set the timestamp @producer side itself
8) set the header to each message and see,-header like co-relation id
make youtube videos on
==========================
kafka offsets

