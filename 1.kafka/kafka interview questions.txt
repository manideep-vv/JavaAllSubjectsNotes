
Horizantally scalable, fault tolerant, distributed
Retru topic- we had a retry topic where we will keep messages when we are unable to process like transient exception - when our target service is down.
DLT-->for un-deserializable messsages we thought of keeping DLTopic, we used to re-attemp the consumption- if that is not transient then we will keep into DLQ

0) batch listener 
1) duplicate message consumption- a consumer before we send the ack to broker if it crashes broker will resend the same msg as it didnt rxd
2) DLT , retry topics
3) Exception - un necessary retries even for Non-transient exceptions - deserialization errors
4) schema registry

kafka-topics.sh --create --replication-factor <replication_factor> --partitions <number_of_partitions> --topic <topic_name> --config retention.ms=<retention_time_in_ms> --config segment.bytes=<segment_size_in_bytes>

.\bin\windows\kafka-topics.bat --create --topic myTopic --partitions 3 --bootstrap-server localhost:9092 --config retention.ms=45000 --config segment.bytes=10000

major issues i faced
=======================
un- necessary retries- in exception handler before attempting a retry  - i used to check if it is transient exception or not

why do we send the key while sending a message-if we dont send it what happens
lets say 10 partitions are there - if i want my message always to go the partitin -1 -then i should send partition num also along with my message- if i dont send partition number ,based on the key partition unmber will be decided
if i dont send the key the alll the messages will be sent to all partitions based on the round robin fashion
if we dont send partition number what will happen -then in which partition the message will go 
let ssay always if i want to send to partition-1 -ans- we should send the partition number also
what is acks=all
minimum ISR list
when a broker will be removed from ISR 
for 10 partitions what kafka will ccreate
what is offset number
how do u locate a message uniquely inside a topic what and all u need- topic+partition num+and offset num
how do u commit the offset
lets say if consumer is back online after some downtime - what will happen
whether it should ask broker for messages or broker will send ok? from where the consmer will ask the messages
he was offline for 5-10 mins , will messages be stored in kafka -if where where all those messages will be 
what is the use of zoo keeper
how many partitions are there in u topic and how many segments and what is the size of each segment
what is ur kafka architecture
if i send a million messages -will producer send each message to kafka broker or what will happen internally
then - produce will have an internal buffer once the buffer capacity is filled then only it will send all msgs to broker
4) if 5 partitions are there with 3 replicas, and we have 5 brokers how arragement will be 
what is the problem if we have only 1 replica?
when can we call it as an In sync replica-if it is max 10 sec behind


consumer
============
if 2 partitions are these ? initialy there was only 1 consumer 
what happens if a consumer suddenly a consumer joins the group ? will he read from first or 
	will that group rebalances? after rebalancing the as first consumer was reading from 2 partitions 
	now 1st consumer will share the offset positions to newly arrived second consumer so that from that offset position that second consumer will read from partition 2 
if one more consumer came to the new consumer group what will happen it will read from first because its a new group



tuning kafka
==============
why kafka is fault tolerant? how its is durable
for fault tolerance what do u do? what if the broker/leader  goes down? 
	-
configure more replicas 
 what if the replicas are behind the leader/ if they are not in sync / - if they are too behind if leader goes down
 as they are behind they cant become leader if we make them leader we may lost messages
 make sure the broker should send acknowledgement back only when all the ISR's also received the message 
 acks=all

for 10 partitions =we should have 10 consumers in that group
performance
=============
if we are sending 1million messages to kafka -internally it will use producer buffer